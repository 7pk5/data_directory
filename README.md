# ğŸ­  Data Directory Collection System

## ğŸŒŸ Overview
An intelligent web-based system for collecting and analyzing company data from any industry sector in India. Features both a command-line interface and a beautiful web interface built with Streamlit.

## âœ¨ Features
- **ğŸŒ Web Interface**: Beautiful Streamlit frontend for easy use
- **ğŸ” Smart Search**: AI-powered query generation for any industry domain
- **ğŸ†“ Free Operation**: Works without paid APIs using intelligent free search
- **ğŸ¤– LLM Enhancement**: Optional Gemini AI for smarter queries and analysis
- **ğŸ“Š Excel Output**: Professional business-ready directories
- **ğŸŒ India-Focused**: All searches target Indian companies and associations
- **ğŸ¯ Custom Domains**: Enter any industry - EdTech, Automotive, Healthcare, etc.

## ğŸš€ Quick Start

### Option 1: Web Interface (Recommended)
```bash
# Install dependencies
pip install -r requirements.txt


### Option 2: Command Line
```bash
python src/main.py
```

## Project Structure
```
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config/          # Configuration files
â”‚   â”œâ”€â”€ scraper/         # Web scraping modules
â”‚   â”œâ”€â”€ analyzer/        # Data analysis and classification
â”‚   â”œâ”€â”€ excel_handler/   # Excel output management
â”‚   â””â”€â”€ utils/           # Utility functions
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/             # Raw search results
â”‚   â”œâ”€â”€ processed/       # Analyzed data
â”‚   â””â”€â”€ output/          # Final Excel files
â”œâ”€â”€ config/              # Domain and prompt configurations
â””â”€â”€ logs/                # Application logs
```

## Setup Instructions

1. **Install Dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

2. **Configure API Keys**:
   Create a `.env` file :
   ```
      # API Configuration
      GEMINI_API_KEY=your_gemini_api_key_here

      # Search Configuration  
      RESULTS_PER_QUERY=15
      SEARCH_DELAY=1
      MAX_RETRIES=3

      # Data Analysis Configuration
      RELEVANCE_THRESHOLD=0.6
      MIN_DATA_ROWS=10

   ```

3. **Run the Application**:
   ```bash
   python main.py
   ```

## Usage
1. Select the domain to search (Chemical, Shipping, Sports, EdTech)
2. The system will generate 29 search queries for the selected domain
3. Automated searching and data collection begins
4. Results are analyzed and classified intelligently
5. Final data is exported to Excel with domain-specific sheets

## Output Format
Each Excel sheet contains:
- Title, URL, Domain, Source Type
- Document Classification
- Data Coverage Estimates
- Extraction Recommendations
- Contact Information
- Relevance Scores
